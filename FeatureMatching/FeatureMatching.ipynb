{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "Image matching can be challenging. \n",
    "1. Local invariant features\t\n",
    "    - Motivation\n",
    "    - Requirements, invariances  \n",
    "2. Keypoint localization  \t\n",
    "    - Harris corner detector  \n",
    "3. Scale invariant region selection  \n",
    "    - Automatic scale selection\t\n",
    "    - Difference-of-Gaussian (DoG) detector\t\n",
    "4. SIFT: an image region descriptor\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Keypoints or interest points detector\n",
    "Keypoints are the same thing as interest points. They are spatial locations, or points in the image that define what is interesting or what stand out in the image. The reason why keypoints are special is because no matter how the image changes... whether the image rotates, shrinks/expands, is translated (all of these would be an affine transformation by the way...) or is subject to distortion (i.e. a projective transformation or homography), you should be able to find the same keypoints in this modified image when comparing with the original image. Here's an example:\n",
    "\n",
    "### General Approach\n",
    "1. Find a set of distinctive key- points. Usually we use the corners.\n",
    "2. Define a region around each keypoint\n",
    "3. Extract and normalize the region content\n",
    "4. Compute a local descriptor from the normalized region\n",
    "5. Match local descriptors\n",
    "\n",
    "<img src='approach.png',width=600,height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harris corner detector\n",
    "<img src='harris.png',width = 600, length = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture Problem  \n",
    "If we see through a small hole, we can only see a subset of the full picture. if we are see the the backgroud, or on the edge, we can't know where this exactly is. Only when we see the edge, we can know for sure since it's unique in this picture\n",
    "<img src = 'aperture.png',width = 500, length = 1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the correlation or SSD\n",
    "f is target image  \n",
    "h is compare image \n",
    "corr is matrix element-wise product  \n",
    "SSD is matrix sum((element-wise difference)^2)\n",
    "<img src = 'cor.png', width= 600, length =600>\n",
    "<img src = 'ssd.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen value\n",
    "```Av = λv ```  \n",
    "λ is eigen value  \n",
    "v is eigen vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
